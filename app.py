# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12jThR62MfXeFvNiy_zOJlcydx6OVRk4g
"""

# app.py

import streamlit as st

from rag_pipeline import get_conversational_chain, format_sources


st.set_page_config(
    page_title="DataTutor - RAG IntroducciÃ³n al AnÃ¡lisis de Datos",
    page_icon="ğŸ“Š",
    layout="wide",
)


@st.cache_resource(show_spinner=True)
def load_chain():
    """
    Carga la chain conversacional una sola vez.
    """
    return get_conversational_chain()


def main():
    st.title("ğŸ“Š DataTutor â€“ Asistente RAG para IntroducciÃ³n al AnÃ¡lisis de Datos")
    st.write(
        """
        Este asistente responde preguntas basÃ¡ndose en los materiales de la materia
        **IntroducciÃ³n al AnÃ¡lisis de Datos** (presentaciones en PDF).

        PodÃ©s hacer preguntas como:
        - *Â¿QuÃ© es un anÃ¡lisis exploratorio de datos?*
        - *Explicame la diferencia entre variables cualitativas y cuantitativas.*
        - *Â¿QuÃ© tipos de grÃ¡ficos recomienda el material para variables categÃ³ricas?*
        """
    )

    # Inicializar estado de sesiÃ³n
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "messages" not in st.session_state:
        st.session_state.messages = []

    chain = load_chain()

    # Mostrar historial de mensajes
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg.get("sources"):
                with st.expander("ğŸ“š Fuentes utilizadas"):
                    for s in msg["sources"]:
                        st.markdown(
                            f"- **Archivo:** `{s['source']}` â€” pÃ¡gina {s['page']}  \n"
                            f"  _Fragmento_: {s['snippet']}..."
                        )

    # Entrada de usuario
    user_input = st.chat_input("EscribÃ­ tu pregunta sobre el material...")
    if user_input:
        # Mostrar mensaje del usuario
        st.session_state.messages.append({"role": "user", "content": user_input})

        with st.chat_message("user"):
            st.markdown(user_input)

        # Ejecutar RAG
        with st.chat_message("assistant"):
            with st.spinner("Buscando en el material y generando respuesta..."):
                result = chain(
                    {
                        "question": user_input,
                        "chat_history": st.session_state.chat_history,
                    }
                )

                answer = result["answer"]
                sources = format_sources(result.get("source_documents", []))

                st.markdown(answer)

                if sources:
                    with st.expander("ğŸ“š Fuentes utilizadas"):
                        for s in sources:
                            st.markdown(
                                f"- **Archivo:** `{s['source']}` â€” pÃ¡gina {s['page']}  \n"
                                f"  _Fragmento_: {s['snippet']}..."
                            )

        # Actualizar historial de chat (para la chain RAG)
        st.session_state.chat_history.append((user_input, answer))

        # Guardar mensaje del asistente en el historial de UI
        st.session_state.messages.append(
            {"role": "assistant", "content": answer, "sources": sources}
        )


if __name__ == "__main__":
    main()